\documentclass[../../main.tex]{subfiles}
\usepackage[italian]{babel}

\begin{document}
    
\chapter{Introduzione}

Il cloud computing é un modello di distribuzione dei servizi informatici che consente di accedere a risorse e applicazioni tramite Internet, senza doverle mantenere localmente sul proprio computer o server. 
Attraverso il cloud computing, le risorse come l'archiviazione dei dati, la potenza di calcolo e il software vengono fornite come servizi virtuali da parte di fornitori specializzati noti come provider di cloud(Amazon,Google ecc.).
Questi provider gestiscono l'infrastruttura fisica e mettono a disposizione degli utenti le risorse necessarie in base alle loro esigenze. In questo modo, le aziende possono evitare di investire in costosi hardware e software, riducendo i costi operativi e aumentando la flessibilitá.

\section{Cloud Computing}
Possiamo distinguere diverse tipologie di servizi cloud in base al tipo di risorse che vengono fornite:
\subsection{Infrastructure as a Service}
L'Infrastructure as a Service (IaaS) é un modello di cloud computing che fornisce risorse informatiche virtualizzate tramite Internet. Con l'IaaS, i provider di cloud mettono a disposizione degli utenti l'infrastruttura fisica necessaria, inclusi server virtuali, storage, reti e altre risorse, consentendo loro di creare e gestire l'ambiente informatico in modo flessibile e scalabile.
Attraverso l'IaaS, gli utenti possono evitare di dover investire in hardware e infrastrutture costose, riducendo i costi di gestione e manutenzione. I provider di cloud si occupano dell'acquisizione, dell'installazione e della gestione dell'hardware, nonché della fornitura delle risorse virtuali agli utenti. Questo modello consente alle aziende di concentrarsi sullo sviluppo delle proprie applicazioni e servizi, piuttosto che preoccuparsi dell'infrastruttura sottostante.
La peculiaritá sta nel fatto che le risorse vengono istanziate su richiesta o domanda di una piattaforma ha bisogno.

\subsection{Platform as a Service}
Il Platform as a Service (PaaS) offre un ambiente di sviluppo e di esecuzione completo per le applicazioni. I provider di cloud mettono a disposizione degli sviluppatori un insieme di strumenti, framework e servizi che semplificano il processo di sviluppo, test e distribuzione delle applicazioni.
PaaS offre un'ampia gamma di strumenti di sviluppo, come linguaggi di programmazione, framework e ambienti di sviluppo integrati (IDE), che semplificano il processo di sviluppo delle applicazioni. Gli sviluppatori possono scrivere il codice, testare e distribuire le applicazioni direttamente nell'ambiente fornito dal PaaS, senza dover configurare manualmente l'infrastruttura.
Alcuni esempi di questo modelli li troviamo in Google App Engine, Microsoft Azure App Service e AWS Elastic Beanstalk.

\subsection{Software as a Service}
Il Software as a Service(SaaS) é modello di cloud computing che fornisce agli utenti applicazioni basate su cloud attraverso Internet. Con il SaaS, i provider di cloud ospitano e gestiscono l'infrastruttura e i software applicativi, consentendo agli utenti di accedere e utilizzare le applicazioni tramite Internet, senza dover installare il software sul proprio computer.
Consiste nell'utilizzo di programmi installati su un server remoto, cioé fuori del computer fisico o dalla LAN locale, spesso attraverso un server web; l'utente puó accedere al programma tramite un browser web, come se fosse un programma installato localmente.
I modelli di pagamento del SaaS sono spesso basati sul consumo effettivo delle risorse, consentendo agli utenti di pagare solo per ció che effettivamente utilizzano. Questo modello di pricing basato su abbonamento o utilizzo puó essere vantaggioso per le aziende, in quanto consentono di evitare costi iniziali elevati e di prevedere meglio i costi operativi.
Alcuni esempi piú comuni di SaaS li troviamo in Google Workspace, Microsoft Office 365, Dropbox.
\subsection{Function As a  Service}
Function as a Service(FaaS) é un modello di cloud computing che consente agli sviluppatori di eseguire e gestire le proprie funzioni senza dover gestire l'infrastruttura sottostante.
In FaaS, gli sviluppatori suddividono le loro applicazioni in funzioni modulari e indipendenti. Ogni funzione esegue un'attivitá specifica e puó essere attivata in risposta a eventi o richieste specifiche. Ad esempio, una funzione puó essere scatenata da un evento di caricamento di un file su un sistema di archiviazione cloud, da una richiesta HTTP o da un timer programmato. Quando una funzione viene attivata, il fornitore di servizi cloud gestisce automaticamente la sua esecuzione, inclusa la gestione delle risorse necessarie. Le funzioni vengono eseguite in ambienti isolati e scalati automaticamente in base alle richieste di carico. Una volta completata l'esecuzione della funzione, le risorse vengono deallocate per massimizzare l'efficienza e minimizzare i costi.
FaaS é diventato un'opzione popolare per lo sviluppo di microservizi, serverless application e scenari di elaborazione event-driven, fornendo un modo flessibile ed efficiente per eseguire singole funzioni di codice.
Alcuni esempi di FaaS li troviamo in AWS Lambda, Google Cloud Functions, Azure Functions.

\subsubsection{Serverless Computing}
Serverless computing rappresenta un paradigma che va oltre il semplice Function-as-a-Service (FaaS), in cui il fornitore di servizi cloud si occupa completamente della gestione dell'infrastruttura sottostante. Il FaaS é un sottoinsieme del Serverless computing che si concentra specificamente sulla gestione delle singole funzioni come entitá indipendenti. In questo contesto, le funzioni vengono eseguite in modo scalabile e senza che l'utente debba preoccuparsi della gestione diretta dell'infrastruttura sottostante.
\autocite{amslaurea24930}

Nel serverless computing, il provider cloud si occuperá di allocare le risorse necessarie per eseguire il codice e di deallocarle una volta terminata l'esecuzione. Questo facilita la distribuzione e la scalabilitá del sistema, cercando di automatizzare quest'ultima fase.
Focalizzandoci in questa gestione delle risorse, viene introdotto un linguaggio cApp che ci permetterá di sincronizzare le risorse attraverso determinate politiche.
\subsection{cApp}
\label{cApp}
Partiamo da un linguaggio dichiarativo APP(\textit{Allocation Priority Policies}) che ci permette di definire politiche di allocazione delle risorse per le funzioni serverless, derivato da un estensione dello scheduler di OpenWhisk.
cApp é un estensione di App, dove le politiche di schedulazioni delle funzioni dipendono dai costi associati alle possibili esecuzioni delle funzioni sui worker disponibili.
\autocite{de2020allocation}.
Vediamo qui di seguito un esempio del funzionamento:
\begin{figure}[H]
   \centering
    \includegraphics{ServerlessSchedulingPoliciesExample.png}
    \caption{Esempio di funzionamento di un sistema serverless \autocite{deserverless}}
\end{figure}
A destra troviamo il codice dichiarativo App che fornisce le regole per allocare le risorse: abbiamo due \textbf{Workers} che sono disponibili, e una strategia che regola come allocare queste risorse nei rispettivi worker; inoltre una \textbf{Strategy} che determina come allocare le risorse e secondo quale prioritá.
Attualmente peró la strategy ci permette di allocare secondo poche strategie generiche gia consolidate.
L'obiettivo diventa ora automatizzare questo processo, adottando procedure automatiche per definire le politiche di allocazione delle risorse basate sulle informazioni derivate dall'analisi statica delle funzioni che dovranno essere eseguite.
Osserviamo adesso un'altro esempio andando ancor di piú in profonditá:
Data una grammatica definita nel paper\autocite {deserverless}, osserviamo alcuni esempi di funzioni:
\begin{lstlisting}[language=Java, caption= La guardia della condizione é un espressione,label={lst:1}]
    (isPremiumUser, par) => {
        if (isPremiumUser) {
           call PremiumService(par)
        } else {
            call BasicService(par)
        }
    }
\end{lstlisting}

Il parametro \textit{isPremiumUser} é un valore che indica se l'utente richiede il servizio premium o meno, e in base a questo valore viene eseguita una chiamata o l'altra.
Di conseguenza assumiamo che il ramo condizionale prende il massimo della latenza tra le due chiamate, non sappiamo staticamente se verrá eseguito il ramo \textit{then} o \textit{else} e quindi non possiamo preventivare il tempo di esecuzione della funzione.

\begin{lstlisting}[language=Java, caption= La guardia della condizione é un'invocazione a un servizio esterno,label={lst:2}]
    (username, par) => {
        if (call isPremiumUser(username)) {
            call PremiumService(par)
        } else {
            call BasicService(par)
        }
    }
\end{lstlisting}

Nel caso sotto riportato invece, se l'utente che scatena l'evento é un membro premium, il tempo di esecuzione previsto dalla funzione é la somma delle latenze delle invocazioni dei servizi \textit{isPremiumUser} e \textit{PremiumService}.
Quindi possiamo preventivare il ritardo atteso(come tempo di esecuzione peggiore), cioé la somma della latenza del servizio \textit{isPremiumUser} piú il massimo tra la latenza dei servizi \textit{PremiumService} e \textit{BasicService}.

\begin{lstlisting}[language=Java, caption=Funzione con logica Map-Reduce,label={lst:3}]
    (jobs, m, r)=>{
        for(i in range(0,m)){
            call Map(jobs, i)
            for(j in range(0,r)){
                call Reduce(jobs, i, j)
            }
        }
    }
\end{lstlisting}
Il parametro jobs descrive una sequenza di lavori map-reduce, dove il numero dei jobs é indicato dal parametro m.
La fase di \textit{Map} che genera m sottotask ``ridotti'' é implementata da un servizio esterno \textit{Map} che riceve jobs e un indice i che indica il job mappato.
Per ogni i, ci sono j sottotask.
In questo caso ci aspettiamo che la latenza dell'intera funzione é data dalla somma di m volte la latenza di \textit{Map} e m $x$ r volte la latenza di \textit{Reduce}.\\

cApp é stato modificato al fine di implementare nuovi costrutti quali \textit{min\_latency} e \textit{max\_latency} che ci permettono di definire un upper bound e un lower bound per la latenza di una funzione.
\begin{multicols}{2}
    \begin{lstlisting}[caption={cAPP for Listing \ref{lst:1} e \ref{lst:2}},label={lst:4}]
-premUser:
    -workers:
        -wrk: W1
        -wrk: W2
    strategy: min_latency
    \end{lstlisting}
    \columnbreak
    \begin{lstlisting}[caption={cApp for Listing~\ref{lst:3}}, label={lst:5}]
-mapReduce:
    -workers:
        -wrk: W1
        -wrk: W2
    strategy: random
    invalidate:
        strategy: max_latency
    \end{lstlisting}
\end{multicols}

Nel Listing \ref{lst:4}, osserviamo come diamo la possibilitá di allocare la funzione \textit{premUser} su due workers, e la strategia di allocazione é quella di minimizzare la latenza, ovvero di dare prioritá al worker su cui la soluzione dell'espressione di costo é minima.
Illustriamo peró meglio le fasi della tecnica di \textit{min\_latency}:
Quando viene creato lo script cApp, viene creata l'associazione tra il codice delle funzioni e il loro script etichettando le funzioni con \textit{//tag:premUser}.
Successivamente abbiamo bisogno del calcolo delle funzioni di costo, il codice delle funzioni viene utilizzato per dedurre i programmi di costo corrispondenti.
Quando le funzioni vengono invocate, possiamo calcolare la soluzione del programma di costo data la conoscenza dei parametri di invocazione.
Quando riceviamo una richiesta ad esempio per il Listing \ref{lst:1} prendiamo il suo programma di costo(rappresentato dal punto di intersezione sinistra) e la corrispondente politica cApp per implementare la politica di schedulazione prevista.
Questa politica puo essere ottenuta in due fasi: Calcolando i programmi di costo dal Solver, eseguendoli in ogni worker, e scegliendo il worker che ha latenza minima per contattare il \textit{PremiumService}.
Invece nel caso del Listing \ref{lst:5} invece abbiamo una strategia di invalidazione \textit{max\_latency}, dopo aver selezionato un worker con una determinata strategia, andiamo a verificare se il worker é in grado di eseguire la funzione andando a risolvere l'espressione di costo corrispondente sostituendo i parametri $m$ e $r$ con la latenza dei servizi \textit{Map} e \textit{Reduce} dal worker selezionato e verifichiamo che la latenza sia inferiore a quella definita nello script.\autocite{deserverless}\\
\begin{figure}[H]
    \includegraphics[width=.9\textwidth]{SchedulingDeployFlow.png}
    \centering
    \caption{From Deploy to Scheduling for Listing \ref{lst:1} e \ref{lst:2} }
\end{figure}
\newpage
\subsubsection{Obiettivo della tesi}
L'obiettivo della tesi è quello di concentrarsi sullo studio delle tecniche che consentono di analizzare la semantica di una funzione scritta in un linguaggio specifico, il quale verrà definito in dettaglio nei capitoli successivi. Questa analisi della semantica è fondamentale per generare le equazioni di costo associate a ciascuna funzione. Le equazioni di costo forniscono informazioni cruciali come la complessità, che rappresenta un upper bound della funzione in questione. Questi dati sono essenziali per ottimizzare lo scheduling dell'esecuzione delle funzioni serverless una volta richieste, consentendo di allocare risorse in modo efficiente e di ridurre i tempi di esecuzione.

Il percorso di ricerca prevede diverse fasi. Inizieremo definendo una grammatica specifica per il linguaggio di programmazione considerato. Successivamente, svilupperemo un interprete per tale linguaggio, il quale analizzerà un programma scritto in un linguaggio ad alto livello e restituirà le equazioni di costo associate a ciascuna funzione. In aggiunta, sarà generato il codice WebAssembly corrispondente, che potrà essere eseguito in un ambiente serverless.

Una volta ottenute le equazioni di costo, procederemo all'analisi dettagliata di ciascuna funzione attraverso l'utilizzo di tool specifici come PUBS (Publications on Upper Bounds Synthesis) e CoFloCo (Cost Flow Complexity Analysis). Questi strumenti, citati rispettivamente in letteratura \autocite{albert2008automatic} e \autocite{flores2014resource}, sono progettati per calcolare l'upper bound delle funzioni date le loro equazioni di costo. Tale analisi ci fornirà una comprensione più approfondita delle prestazioni delle funzioni, consentendoci di ottimizzare ulteriormente l'allocazione delle risorse e migliorare il processo di scheduling delle esecuzioni.
\end{document}